{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting Fake are Real News - Modeling and testing \n",
    "\n",
    "\n",
    "                                By: Muluemebet Ayalew \n",
    "                                    June, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # to use regular expression pattern \n",
    "import datetime as dt  # to parse to datetime\n",
    "import string\n",
    "from scipy import stats\n",
    "\n",
    "#text processing and visualization\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize, TweetTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords          # to access stop words \n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer   # for lemmatization or steming\n",
    "\n",
    "import spacy\n",
    "from gensim.corpora.dictionary import Dictionary   # to map token , id and create corpus\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud,STOPWORDS # to visualize frequeent words \n",
    "from gensim.models import  Word2Vec  #  word embeding \n",
    "from gensim.models.phrases import Phraser, Phrases # to use for bigram modeling,\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.tfidfmodel import TfidfModel # tfidf using gensim\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # to make word vectors \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# For modeling and evaluation \n",
    "from sklearn.naive_bayes import MultinomialNB  # for Naive Baye's  classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics # to evaluate model performance\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true= pd.read_csv(\"True.csv\", parse_dates=[\"date\"])     # the true news data\n",
    "fake= pd.read_csv(\"Fake.csv\")     # the fake news data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "\n",
       "                                                text       subject       date  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews 2017-12-31  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews 2017-12-29  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews 2017-12-31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head(3) # the first few rows of real dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape # shape of real news before adding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head() # the first few rows of fake dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape  # shape of fake news before adding label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Add labels(fake/true) to the  dataframs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called is_fake and label as 0 for true news \n",
    "true[\"label\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called is_fake and label as 1 for fake news \n",
    "fake[\"label\"]= \"fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the date column into datetime. \n",
    "#Since it has two datetime format, we need two formats to parse.  \n",
    "def parsing_datetime(string):\n",
    "    for f in (\"%B %d, %Y\", '%d-%b-%y', \"%b %d, %Y\"): # format  19-Feb-18\n",
    "        try:\n",
    "            return dt.datetime.strptime(string, f)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "# parse the date column of fake dataframe into datetime\n",
    "fake.date= fake.date.apply(lambda x: parsing_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "\n",
       "                                                text       subject       date  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews 2017-12-31   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews 2017-12-29   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews 2017-12-31   \n",
       "\n",
       "  label  \n",
       "0  true  \n",
       "1  true  \n",
       "2  true  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "\n",
       "                                                text subject       date label  \n",
       "0  Donald Trump just couldn t wish all Americans ...    News 2017-12-31  fake  \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News 2017-12-31  fake  \n",
       "2  On Friday, it was revealed that former Milwauk...    News 2017-12-30  fake  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2)  Merge the real and fake dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the fake and read dataframe\n",
    "news= pd.concat([true,fake], axis=0).reset_index() # reset index to have unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44619</th>\n",
       "      <td>23202</td>\n",
       "      <td>FBI Director Comey’s ‘Leaked’ Memo Explains Wh...</td>\n",
       "      <td>21st Century Wire says 21WIRE reported on Frid...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>11142</td>\n",
       "      <td>White House welcomes U.S. court ruling on carb...</td>\n",
       "      <td>WASHINGTON (Reuters) - The White House said on...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28925</th>\n",
       "      <td>7508</td>\n",
       "      <td>Kansas Republican Bill Would Give GOP Power T...</td>\n",
       "      <td>If Kansas Republicans have their way, they wil...</td>\n",
       "      <td>News</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>17542</td>\n",
       "      <td>OOPS! Lindsey Vonn Gets Hit With Big Dose Of K...</td>\n",
       "      <td>Only 3 days ago, Lindsey Vonn told CNN that sh...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>17905</td>\n",
       "      <td>Afghan-Pakistan border villages brace for Berl...</td>\n",
       "      <td>CHAMAN/QUETTA, Pakistan (Reuters) - Thousands ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                              title  \\\n",
       "44619  23202  FBI Director Comey’s ‘Leaked’ Memo Explains Wh...   \n",
       "11142  11142  White House welcomes U.S. court ruling on carb...   \n",
       "28925   7508   Kansas Republican Bill Would Give GOP Power T...   \n",
       "38959  17542  OOPS! Lindsey Vonn Gets Hit With Big Dose Of K...   \n",
       "17905  17905  Afghan-Pakistan border villages brace for Berl...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "44619  21st Century Wire says 21WIRE reported on Frid...   Middle-east   \n",
       "11142  WASHINGTON (Reuters) - The White House said on...  politicsNews   \n",
       "28925  If Kansas Republicans have their way, they wil...          News   \n",
       "38959  Only 3 days ago, Lindsey Vonn told CNN that sh...     left-news   \n",
       "17905  CHAMAN/QUETTA, Pakistan (Reuters) - Thousands ...     worldnews   \n",
       "\n",
       "            date label  \n",
       "44619 2016-10-29  fake  \n",
       "11142 2016-01-21  true  \n",
       "28925 2016-03-13  fake  \n",
       "38959 2017-12-09  fake  \n",
       "17905 2017-10-10  true  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.sample(5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.index.is_unique # we have unique index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot the number of fake and real news\n",
    "_=news.label.value_counts().plot(kind=\"bar\", title=\"Frequency of Fake and Real News\")\n",
    "_=plt.ylabel(\"Number of News\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)  Data Cleaning and preprocessing:\n",
    "Removing html tags, url links, specal characters, punctuations, emoji and stopwords. Though CountVectorizer handles stop words , special characters and punctuation, the cleaning was done before it. \n",
    "\n",
    "The function remove_pattern is defiend to remove certain patterns from the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function to remove patterns(emoji, url, html , special characteres, punctuations, .....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patterns= [emoji, url, html]\n",
    "def remove_pattern(text, patterns):\n",
    "    \"\"\"The function remove_pattern returns the new string with a set of patterns removed.\n",
    "       Parameters:\n",
    "       ------------\n",
    "       data: the text from which the pattern will be removed\n",
    "       patterns: is the set of patterns(iterable) we are intereted to remove from the text\n",
    "       \"\"\"\n",
    "           \n",
    "    for pattern in patterns:\n",
    "        new= re.sub(pattern, \"\", text)\n",
    "        text= new \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns to be extracted and to be removed from the data \n",
    "emoji = \"[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF\\U000024C2-\\U0001F251]+\"\n",
    "\n",
    "url= re.compile(\"https?://\\S+|www\\.\\S+\")                     # pattern for url\n",
    "html= r'<.*?>'                                               # pattern for html tag\n",
    "num_with_text= r\"\\S*\\d+\\S*\"                                  # pattern for digit \n",
    "punctuation= r\"[#@&%$~=\\.;:\\?,(){}\\\"\\“\\”\\‘\\'\\*!\\+`^<>\\[\\]\\-]+\"      #pattern for punctuations and special characters   \n",
    "apostroph=r\"\\’s?\"\n",
    "# collect the patterns \n",
    "patterns=[emoji, url, html, num_with_text, punctuation, apostroph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Clean merged data\n",
    "At this statage of data cleaning ,the emoji, url links, html tag, digits and special characters and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the title of merged data using regular expression patterns\n",
    "news_clean_title = news.title.apply(remove_pattern, patterns= patterns)\n",
    "news_clean_text= news.text.apply(remove_pattern, patterns= patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords \n",
    "Stopwords are worlds commonly appeared in a text with no significant information about it. For example 'a', 'the','of' etc. Gensim library has stopwords and a function to remove stopwords. Here, I implement two step process to remove stopwords. First, using remove_stopwords() from gensim.parsing.preprocessing module. And second, using stopwords from wordcloud module. Since the words in the text are affacted by data cleaning technique such as removing punctutions, we need to format the stopwords in the same way we cleaned the data. For example it has a stopeword \"you'll\". It will be changed in to \"youll\" after removing the apostrophe. Thus, the stopewords should have the same format to ignoure them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, preprocess_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords and multiple whitespaces from the news title\n",
    "nostopword_title= news_clean_title.apply(remove_stopwords).apply(strip_multiple_whitespaces) \n",
    "# remove stopwords and multiple whitespaces from the news title\n",
    "nostopword_text= news_clean_text.apply(remove_stopwords).apply(strip_multiple_whitespaces)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization \n",
    "Split the text into words by white space. Here, the text are also converted into lowercase and stopwords are removed for the second time after the punctuations were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_stopword=[re.sub(\"\\'\", \"\", word)  for word in STOPWORDS] # stopwords are from wordcloud library \n",
    "formated_stopword # remove apostrophe from stopwords to match with stopwords in the text after punctuations removed \n",
    "def tokenize_without_stopwords(data): # remove stopword, make lower case , split the text a\n",
    "    tokens=[]\n",
    "    for word in data.lower().split():\n",
    "        if word not in formated_stopword:\n",
    "            tokens.append(word)\n",
    "    return tokens      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets for phrase modeling and word embeding :** The following tokenized datasets will be used later for phrase modeling. The wordembeding is also done based on this data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting word tokens in lower case without stopwords, this is used later for phrase modeling and word embeding \n",
    "data_title= nostopword_title.apply(tokenize_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting word tokens in lower case without stopwords, this data is later used for phrase modeling and word embeding  \n",
    "data_text=nostopword_text.apply(tokenize_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [us, budget, fight, looms, republicans, flip, ...\n",
       "1    [us, military, accept, transgender, recruits, ...\n",
       "2    [senior, us, republican, senator, let, mr, mue...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title.head(3)  # look at the tokenized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets to make  countvector and tfidf:**\n",
    "Make ready the data for modeling by concatenating the tokenized words into a single text.\n",
    "These data are used later for modeling using countvector and tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ready the data for modeling by concatenating the tokenized words into a single text.\n",
    "#These data are used later for modeling using countvector  and tfidf  \n",
    "clean_title = data_title.apply(lambda x: \" \".join(x))\n",
    "clean_text = data_text.apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    us budget fight looms republicans flip fiscal ...\n",
       "1    us military accept transgender recruits monday...\n",
       "2      senior us republican senator let mr mueller job\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_title.head(3) # look at the cleaned titles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2)  Creating Custom  Word Embeddings using Word2Vec\n",
    "Though it is possible to have pre-trainied models using spacy or gensim, here I am interested to create a custom word embeding to see if there is performance diffence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase detection \n",
    "The text is coverted into lowercase to avoid case sensitivity. Make sure that the new data to be transformed using this model has to be in lower case before transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases = Phrases(sentences, min_count=1, threshold=1)\n",
    "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "# Create the relevant phrases from the list of sentences:\n",
    "phrases = Phrases(data_title, common_terms=common_terms)\n",
    "# The Phraser object is used to transform sentences\n",
    "bigram_ttl = Phraser(phrases)\n",
    "\n",
    "all_title = list(bigram_ttl[data_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['us', 'budget', 'fight', 'looms', 'republicans', 'flip', 'fiscal', 'script'],\n",
       " ['us', 'military', 'accept', 'transgender', 'recruits', 'monday', 'pentagon'],\n",
       " ['senior', 'us', 'republican_senator', 'let', 'mr', 'mueller', 'job']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_title[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president', 'barack_obama']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_ttl[[\"president\",\"barack\",\"obama\"]] # check for using new word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(data_text, common_terms=common_terms)\n",
    "# The Phraser object is used to transform sentences\n",
    "bigram_txt = Phraser(phrases)\n",
    "\n",
    "all_text = list(bigram_txt[data_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['washington_reuters', 'head', 'conservative', 'republican', 'faction']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[0][:5] #the first row(news) with some tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save / load an exported collocation model\n",
    "#bigram_txt.save(\"bigram_model_txt.pkl\")\n",
    "#bigram_reloaded = Phraser.load(\"bigram_model_txt.pkl\")\n",
    "#bigram_reloaded[[\"donald\", \"trump\" ,\"is\", \"a\", \"president\"]]  # apply the exported model to a sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization and stemming\n",
    "Lemmatization and stemming was applied for the data set. However, some words were modefied by lemmatization and phrase detection was not efficent after stemming. Therefore, the results of lemmatization and stemming were not included in the next step of the  analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "porter_stemmer = PorterStemmer() # from nltk.stem library\n",
    "def stemming(doc):\n",
    "    \"\"\"returns the stemming list of words\"\"\"\n",
    "    stem=[]\n",
    "    for word in doc:\n",
    "        stem.append(porter_stemmer.stem(word))\n",
    "    return stem\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() # from nltk.stem library\n",
    "def lemmatize(doc):\n",
    "    \"\"\"returns lemmatized list of words\"\"\"\n",
    "    lemma=[]\n",
    "    for word in doc:\n",
    "        lemma.append(lemmatizer.lemmatize(word))\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title_stem =[stemming(doc) for doc in all_title] # stemming the words in the title after phrase modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_stem =[stemming(doc) for doc in all_text] # stemming the words in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['us', 'budget', 'fight', 'loom', 'republican', 'flip', 'fiscal', 'script'],\n",
       " ['us', 'militari', 'accept', 'transgend', 'recruit', 'monday', 'pentagon'],\n",
       " ['senior', 'us', 'republican_sen', 'let', 'mr', 'mueller', 'job']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title_stem[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title_lemma=data_title.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [u, budget, fight, loom, republican, flip, fis...\n",
       "1    [u, military, accept, transgender, recruit, mo...\n",
       "2    [senior, u, republican, senator, let, mr, muel...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title_lemma.head(3) # lemmatization removes 's' from 'us' and make it 'u' doesn't make sense "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec representation of words in the news title \n",
    "w2v_title = Word2Vec(all_title, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=200,      # Dimensionality of word embeddings\n",
    "                 workers=2,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec representation of words in the news text \n",
    "w2v_text = Word2Vec(all_text, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=200,      # Dimensionality of word embeddings\n",
    "                 workers=2,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word2vector for title of news  : Word2Vec(vocab=13993, size=200, alpha=0.025)\n",
      "Size of word2vector for text of news : Word2Vec(vocab=120808, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of word2vector for title of news  :\", w2v_title) # shape of the word2vector\n",
    "print(\"Size of word2vector for text of news :\",w2v_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "w2v_text.save(\"w2v_text\")\n",
    "#txtw2v= Word2Vec.load(\"w2v_text\") # toload the saved word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('united_states', 0.5919766426086426),\n",
       " ('obama_administration', 0.39245516061782837),\n",
       " ('pentagon', 0.37952154874801636),\n",
       " ('american', 0.37035509943962097),\n",
       " ('countries', 0.36579960584640503),\n",
       " ('washington', 0.3629639744758606),\n",
       " ('openended', 0.362476646900177),\n",
       " ('iran_complying', 0.3541705310344696),\n",
       " ('discourage_imports', 0.33896613121032715),\n",
       " ('impose_targeted', 0.32720041275024414)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_text.wv.most_similar([\"us\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_text.wv.__getitem__(\"us\") ;# see word vector for 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'said', 'trump', 'us', 'people', 'president', 'government', 't']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary=w2v_text.wv.index2word\n",
    "vocabulary[:8] # list of words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Convert  Word2vec to feature vectors  \n",
    "To use word vectors obtained from word2vec, the following functions are defined. Frist, the vectors of each word found in a news are summed up and then divided the number of words appeared in a news(the first function does this). Then, we do this for the entire data set(the second function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from a web and adapted a littel bit \n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \"\"\"returns mean feature vector for each news\"\"\"\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words: # loop over words in a tokenized news\n",
    "        if word in vocabulary: # check if the word in the vocabulary of word2vec\n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv.__getitem__(word)) # add vectors in a\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    \"\"\"returns mean feature vector for the whole data set\"\"\"\n",
    "    \n",
    "    vocabulary = set(model.wv.index2word) #vocabulary of word2vec\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size=200\n",
    "corpus_txt= all_text # list of words in list of news\n",
    "corpus_ttl=all_title # list of list for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document level embeddings\n",
    "w2v_feature_array_ttl = averaged_word_vectorizer(corpus=corpus_ttl, model=w2v_title,\n",
    "                                             num_features=feature_size)\n",
    "w2v_feature_ttl= pd.DataFrame(w2v_feature_array_ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document level embeddings\n",
    "w2v_feature_array_txt = averaged_word_vectorizer(corpus=corpus_txt, model=w2v_text,\n",
    "                                             num_features=feature_size)\n",
    "w2v_feature_txt= pd.DataFrame(w2v_feature_array_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the feature vectors \n",
    "w2v_feature_ttl.to_csv(\"w2v_feature_ttl.csv\", index=False)\n",
    "w2v_feature_txt.to_csv(\"w2v_feature_txt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.153727</td>\n",
       "      <td>-0.732860</td>\n",
       "      <td>0.303991</td>\n",
       "      <td>0.720534</td>\n",
       "      <td>-0.305186</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>-0.502959</td>\n",
       "      <td>0.692310</td>\n",
       "      <td>0.311424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083251</td>\n",
       "      <td>0.638944</td>\n",
       "      <td>0.070788</td>\n",
       "      <td>-0.225303</td>\n",
       "      <td>-0.504064</td>\n",
       "      <td>0.370588</td>\n",
       "      <td>0.644337</td>\n",
       "      <td>-0.511604</td>\n",
       "      <td>0.106932</td>\n",
       "      <td>-0.076643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087173</td>\n",
       "      <td>-0.139868</td>\n",
       "      <td>-0.287196</td>\n",
       "      <td>0.867798</td>\n",
       "      <td>-0.521753</td>\n",
       "      <td>0.216526</td>\n",
       "      <td>0.278204</td>\n",
       "      <td>-0.230697</td>\n",
       "      <td>0.408122</td>\n",
       "      <td>-0.019542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124385</td>\n",
       "      <td>0.188996</td>\n",
       "      <td>0.043933</td>\n",
       "      <td>-0.589713</td>\n",
       "      <td>-0.328999</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>0.391701</td>\n",
       "      <td>-0.511506</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.012462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.370391</td>\n",
       "      <td>-0.587086</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.645089</td>\n",
       "      <td>-0.540356</td>\n",
       "      <td>-0.335689</td>\n",
       "      <td>0.917892</td>\n",
       "      <td>-0.367188</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.326747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071384</td>\n",
       "      <td>0.191012</td>\n",
       "      <td>0.222434</td>\n",
       "      <td>-0.719496</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.077755</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>-0.229202</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>-0.244885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.153727 -0.732860  0.303991  0.720534 -0.305186 -0.015977  0.153944   \n",
       "1  0.087173 -0.139868 -0.287196  0.867798 -0.521753  0.216526  0.278204   \n",
       "2 -0.370391 -0.587086  0.024770  0.645089 -0.540356 -0.335689  0.917892   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.502959  0.692310  0.311424  ...  0.083251  0.638944  0.070788 -0.225303   \n",
       "1 -0.230697  0.408122 -0.019542  ... -0.124385  0.188996  0.043933 -0.589713   \n",
       "2 -0.367188  0.829467  0.326747  ... -0.071384  0.191012  0.222434 -0.719496   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.504064  0.370588  0.644337 -0.511604  0.106932 -0.076643  \n",
       "1 -0.328999  0.087015  0.391701 -0.511506  0.000607  0.012462  \n",
       "2  0.003930 -0.077755  0.140970 -0.229202  0.171507 -0.244885  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_feature_txt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load the saved data\n",
    "w2v_feature_ttl=pd.read_csv(\"w2v_feature_ttl.csv\")\n",
    "w2v_feature_txt=pd.read_csv(\"w2v_feature_txt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5)  Split the data into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) without cleaning the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= news.drop([\"subject\",\"date\", \"label\"], axis=1) # potential predictors \n",
    "y= news[\"label\"]              # outcome variable\n",
    "# Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=40, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train (31428, 3)\n",
      "y-train (31428,)\n",
      "X-test (13470, 3)\n",
      "y-test (13470,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X-train\", X_train.shape)\n",
    "print(\"y-train\", y_train.shape)\n",
    "\n",
    "print(\"X-test\", X_test.shape)\n",
    "print(\"y-test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) With cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ttl=clean_title \n",
    "X_txt=clean_text\n",
    "\n",
    "y= news[\"label\"]  # outcome variable\n",
    "\n",
    "# Split the data into training and test data for title\n",
    "X_train_ttl, X_test_ttl, y_train_ttl, y_test_ttl= train_test_split(X_ttl, y, test_size=0.3,random_state=40, stratify=y)\n",
    "\n",
    "# Split the data into training and test data for text\n",
    "X_train_txt, X_test_txt, y_train_txt, y_test_txt= train_test_split(X_txt, y, test_size=0.3,random_state=40, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train (31428,)\n",
      "y-train (31428,)\n",
      "X-test (13470,)\n",
      "y-test (13470,)\n"
     ]
    }
   ],
   "source": [
    "# check the split \n",
    "print(\"X-train\", X_train_ttl.shape)\n",
    "print(\"y-train\", y_train_ttl.shape)\n",
    "print(\"X-test\", X_test_ttl.shape)\n",
    "print(\"y-test\", y_test_ttl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) With word2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_ttl, X_test_w2v_ttl, y_train_w2v_ttl, y_test_w2v_ttl\\\n",
    "                        =train_test_split(w2v_feature_ttl, y, test_size=0.3, random_state=40, stratify=y)\n",
    "\n",
    "X_train_w2v_txt, X_test_w2v_txt, y_train_w2v_txt, y_test_w2v_txt\\\n",
    "                        =train_test_split(w2v_feature_txt,y, test_size=0.3,random_state=40, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Making Classification Models\n",
    "\n",
    "A total of 18 models were fitted with differnt senarios. The first 16 were made with a combination of without cleaned data or with cleaned data, using word count or tfidf, and using logistic regression or multinomial naive bayes. The last two are made using vectores derived from word embeding technique.\n",
    "Hyperparameters for logistic regression and multinomial naive bayes were tuned using grid search cross validation. The regularization parameter \"C\" for logistic regression is set to 0.8 for all models for simplicity as it has very similar similar result with the tured values. The parameters used for multinomial naive bayes are obtained from grid search and the detained is found in section 6.5(Parameter tunning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_vector(x_train, x_test, vectorizer):\n",
    "    \"\"\"Returns the vector of training and test data from the given column using the specified vectorizor.\n",
    "    \n",
    "    parameter:\n",
    "    ----------------\n",
    "            X_train/X_test: training and test data, respectively\n",
    "            vectorizore: could be countVectorizer or TfidfVectorizer to vectorize the text.\n",
    "    \"\"\"        \n",
    "    #Instantiate CountVectorizer object \n",
    "    count_v= vectorizer(min_df=3, stop_words=\"english\")\n",
    "\n",
    "    # Transform the training data using only the given column values\n",
    "    count_train = count_v.fit_transform(x_train)\n",
    "\n",
    "    # Transform the test data using only the given column values\n",
    "    count_test = count_v.transform(x_test)\n",
    "    \n",
    "    return count_train, count_test\n",
    "\n",
    "\n",
    "def model_vect(x_train, x_test, ytrain, ytest, vectorizer, model_name):   # X= news[\"text\"]  # use text column as predictor \n",
    "    \"\"\"The function model_vect returns the performance of a classification model using \n",
    "    a specified vectorizer of trianing and test data sets\n",
    "    \n",
    "    parameter :\n",
    "        X_train/X_test: training and test predictor data, respectively \n",
    "        ytrain/ytest : training and test outcome labels, respectively\n",
    "        model_name: instance of classiication machine learning method used\n",
    "        vectorizer: the name of the vectorizer used (CountVectorizer/TfidfVectorizer)\n",
    "       \n",
    "   \"\"\"  \n",
    "    count_train, count_test= get_vector(x_train, x_test, vectorizer) \n",
    "            \n",
    "    # fit the trianining data with a machine learning method\n",
    "    model=model_name.fit(count_train,ytrain)\n",
    "        \n",
    "    # predict for test data \n",
    "    pred= model.predict(count_test)\n",
    "    \n",
    "    # return the classification report: cm\n",
    "    #cm=metrics.classification_report(ytest, pred, labels=[\"true\",\"fake\"])\n",
    "    cm= metrics.confusion_matrix(ytest, pred, labels=[\"true\",\"fake\"]) # confusion matrix\n",
    "    print(cm)\n",
    "    return(metrics.accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.1) Classification based on non-cleaned data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.1.1) Classification based on the title of the news\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling title using word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5941  484]\n",
      " [ 357 6688]]\n",
      "0.9375649591685227\n",
      "\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6162  263]\n",
      " [ 459 6586]]\n",
      "0.9463994060876021\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_noclean_NB= model_vect(X_train[\"title\"], X_test[\"title\"], y_train, y_test,CountVectorizer, MultinomialNB(alpha=0.5))\n",
    "print(acc_ttl_noclean_NB)\n",
    "print(\"\\n\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_noclean_lreg= model_vect(X_train[\"title\"], X_test[\"title\"],y_train, y_test,CountVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_ttl_noclean_lreg)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling title using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5889  536]\n",
      " [ 347 6698]]\n",
      "0.9344469190794358\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6111  314]\n",
      " [ 487 6558]]\n",
      "0.9405345211581292\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_nocln_tfidf_NB= model_vect(X_train[\"title\"], X_test[\"title\"],y_train, y_test,TfidfVectorizer, MultinomialNB(alpha=0.5))\n",
    "print(acc_ttl_nocln_tfidf_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_nocln_tfidf_lreg= model_vect(X_train[\"title\"], X_test[\"title\"],y_train, y_test,TfidfVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_ttl_nocln_tfidf_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2)Classification based on the text of the news \n",
    "#### Modeling text using word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[6068  357]\n",
      " [ 312 6733]]\n",
      "0.9503340757238308\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6399   26]\n",
      " [  32 7013]]\n",
      "0.9956941351150705\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_noclean_NB= model_vect(X_train[\"text\"], X_test[\"text\"],y_train, y_test, CountVectorizer, MultinomialNB(alpha=0.001))\n",
    "print(acc_txt_noclean_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_noclean_lreg= model_vect(X_train[\"text\"], X_test[\"text\"],y_train, y_test,CountVectorizer, LogisticRegression(C=0.8, max_iter=200))\n",
    "print(acc_txt_noclean_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling text using tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5914  511]\n",
      " [ 335 6710]]\n",
      "0.9371937639198218\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6355   70]\n",
      " [ 144 6901]]\n",
      "0.984112843355605\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_nocln_tfidf_NB=model_vect(X_train[\"text\"], X_test[\"text\"],y_train, y_test,TfidfVectorizer, MultinomialNB(alpha=0.001))\n",
    "print(acc_txt_nocln_tfidf_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_nocln_tfidf_lreg= model_vect(X_train[\"text\"], X_test[\"text\"],y_train, y_test,TfidfVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_txt_nocln_tfidf_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) Classification using cleaned data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling title using word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5942  483]\n",
      " [ 365 6680]]\n",
      "0.9370452858203415\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6143  282]\n",
      " [ 479 6566]]\n",
      "0.9435040831477357\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_clean_NB= model_vect(X_train_ttl, X_test_ttl, y_train_ttl, y_test_ttl,CountVectorizer, MultinomialNB(alpha=0.5))\n",
    "print(acc_ttl_clean_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_clean_lreg= model_vect(X_train_ttl, X_test_ttl, y_train_ttl, y_test_ttl,CountVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_ttl_clean_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling title using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5886  539]\n",
      " [ 355 6690]]\n",
      "0.933630289532294\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6087  338]\n",
      " [ 499 6546]]\n",
      "0.9378619153674833\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_clean_tfidf_NB= model_vect(X_train_ttl, X_test_ttl, y_train_ttl, y_test_ttl,TfidfVectorizer, MultinomialNB(alpha=0.5))\n",
    "print(acc_ttl_clean_tfidf_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_ttl_clean_tfidf_lreg= model_vect(X_train_ttl, X_test_ttl, y_train_ttl, y_test_ttl,TfidfVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_ttl_clean_tfidf_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling text using word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[6058  367]\n",
      " [ 231 6814]]\n",
      "0.9556050482553823\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6405   20]\n",
      " [  25 7020]]\n",
      "0.9966592427616926\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_clean_NB= model_vect(X_train_txt, X_test_txt, y_train_txt, y_test_txt,CountVectorizer, MultinomialNB(alpha=0.001))\n",
    "print(acc_txt_clean_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_clean_lreg=model_vect(X_train_txt, X_test_txt, y_train_txt, y_test_txt,CountVectorizer, LogisticRegression(C=0.8, max_iter=200))\n",
    "print(acc_txt_clean_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling text using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Naive Baye's Classifier Performance \u001b[0m\n",
      "\n",
      "[[5943  482]\n",
      " [ 232 6813]]\n",
      "0.9469933184855234\n",
      "\u001b[1m Logistic Regression Classifier Performance \u001b[0m\n",
      "\n",
      "[[6354   71]\n",
      " [ 127 6918]]\n",
      "0.9853006681514477\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m Naive Baye's Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_clean_tfidf_NB= model_vect(X_train_txt, X_test_txt, y_train_txt, y_test_txt,TfidfVectorizer, MultinomialNB(alpha=0.001))\n",
    "print(acc_txt_clean_tfidf_NB)\n",
    "print(\"\\033[1m Logistic Regression Classifier Performance \\033[0m\\n\")\n",
    "acc_txt_clean_tfidf_lreg=model_vect(X_train_txt, X_test_txt, y_train_txt, y_test_txt,TfidfVectorizer, LogisticRegression(C=0.8))\n",
    "print(acc_txt_clean_tfidf_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3) Using word2vec features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5999  426]\n",
      " [ 453 6592]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true       0.93      0.93      0.93      6425\n",
      "        fake       0.94      0.94      0.94      7045\n",
      "\n",
      "    accuracy                           0.93     13470\n",
      "   macro avg       0.93      0.93      0.93     13470\n",
      "weighted avg       0.93      0.93      0.93     13470\n",
      "\n",
      "Accuracy =  0.9347438752783964\n"
     ]
    }
   ],
   "source": [
    "# using only the title of the text\n",
    "lreg_ttl= LogisticRegression(C=0.8, max_iter=200)\n",
    "lreg_model_ttl= lreg_ttl.fit(X_train_w2v_ttl,y_train_w2v_ttl)\n",
    "pred_tst_ttl= lreg_model_ttl.predict(X_test_w2v_ttl)\n",
    "print(metrics.confusion_matrix(y_test_w2v_ttl, pred_tst_ttl, labels=[\"true\",\"fake\"]))\n",
    "print(metrics.classification_report(y_test_w2v_ttl, pred_tst_ttl, labels=[\"true\",\"fake\"]))\n",
    "acc_w2v_ttl= metrics.accuracy_score(y_test_w2v_ttl, pred_tst_ttl)\n",
    "print(\"Accuracy = \", acc_w2v_ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6324  101]\n",
      " [ 172 6873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true       0.97      0.98      0.98      6425\n",
      "        fake       0.99      0.98      0.98      7045\n",
      "\n",
      "    accuracy                           0.98     13470\n",
      "   macro avg       0.98      0.98      0.98     13470\n",
      "weighted avg       0.98      0.98      0.98     13470\n",
      "\n",
      "0.9797327394209354\n"
     ]
    }
   ],
   "source": [
    "# modeling text using logistic regression \n",
    "lreg_txt= LogisticRegression(C=0.8, max_iter=200)\n",
    "lreg_model_txt= lreg_txt.fit(X_train_w2v_txt,y_train_w2v_txt)\n",
    "pred_tst_txt= lreg_model_txt.predict(X_test_w2v_txt)\n",
    "print(metrics.confusion_matrix(y_test_w2v_txt, pred_tst_txt, labels=[\"true\",\"fake\"]))\n",
    "print(metrics.classification_report(y_test_w2v_txt, pred_tst_txt, labels=[\"true\",\"fake\"]))\n",
    "acc_w2v_txt= metrics.accuracy_score(y_test_w2v_txt, pred_tst_txt)\n",
    "print(acc_w2v_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4) Model performanc summary \n",
    "The performace of different models were compaired my measureing thier performance(accuracy) for test data set. The aaccuracy of all the models are summurized here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring together the accuracy of all models \n",
    "models= [acc_ttl_noclean_NB, acc_ttl_noclean_lreg, acc_ttl_nocln_tfidf_NB, acc_ttl_nocln_tfidf_lreg, acc_txt_noclean_NB,\n",
    "acc_txt_noclean_lreg, acc_txt_nocln_tfidf_NB, acc_txt_nocln_tfidf_lreg, acc_ttl_clean_NB, acc_ttl_clean_lreg,\n",
    "acc_ttl_clean_tfidf_NB, acc_ttl_clean_tfidf_lreg, acc_txt_clean_NB, acc_txt_clean_lreg, acc_txt_clean_tfidf_NB, \n",
    "acc_txt_clean_tfidf_lreg, acc_w2v_ttl, acc_w2v_txt]\n",
    "\n",
    "# the name of the models\n",
    "name= [\"noclean_title_NB\", \"noclean_title_lreg\", \"noclean_title_tfidf_NB\", \"noclean_title_tfidf_lreg\", \"noclean_text_NB\",\n",
    "\"noclean_text_lreg\", \"noclean_text_tfidf_NB\", \"noclean_text_tfidf_lreg\", \"clean_title_NB\", \"clean_title_lreg\",\n",
    "\"clean_title_tfidf_NB\", \"clean_title_tfidf_lreg\", \"clean_text_NB\", \"clean_text_lreg\", \"clean_text_tfidf_NB\", \n",
    "\"clean_text_tfidf_lreg\", \"w2v_ttl\", \"w2v_txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[noclean, title, NB]</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[noclean, title, lreg]</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[noclean, title, tfidf, NB]</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[noclean, title, tfidf, lreg]</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[noclean, text, NB]</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[noclean, text, lreg]</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[noclean, text, tfidf, NB]</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[noclean, text, tfidf, lreg]</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[clean, title, NB]</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[clean, title, lreg]</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[clean, title, tfidf, NB]</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[clean, title, tfidf, lreg]</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[clean, text, NB]</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[clean, text, lreg]</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[clean, text, tfidf, NB]</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[clean, text, tfidf, lreg]</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[w2v, ttl]</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[w2v, txt]</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy\n",
       "0            [noclean, title, NB]     0.938\n",
       "1          [noclean, title, lreg]     0.946\n",
       "2     [noclean, title, tfidf, NB]     0.934\n",
       "3   [noclean, title, tfidf, lreg]     0.941\n",
       "4             [noclean, text, NB]     0.950\n",
       "5           [noclean, text, lreg]     0.996\n",
       "6      [noclean, text, tfidf, NB]     0.937\n",
       "7    [noclean, text, tfidf, lreg]     0.984\n",
       "8              [clean, title, NB]     0.937\n",
       "9            [clean, title, lreg]     0.944\n",
       "10      [clean, title, tfidf, NB]     0.934\n",
       "11    [clean, title, tfidf, lreg]     0.938\n",
       "12              [clean, text, NB]     0.956\n",
       "13            [clean, text, lreg]     0.997\n",
       "14       [clean, text, tfidf, NB]     0.947\n",
       "15     [clean, text, tfidf, lreg]     0.985\n",
       "16                     [w2v, ttl]     0.935\n",
       "17                     [w2v, txt]     0.980"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discription=[n.split(\"_\") for n in name]  # split the name to get more sense of it\n",
    "summary= pd.DataFrame(zip(discription,np.round(models, decimals=3)), columns=[\"Model\", \"Accuracy\"])\n",
    "summary.to_csv(\"all_pred_summary.csv\", index=False) # save the result\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5) Test using 2017 archived news titles from Snopes\n",
    "Snopes is a fact-checking website. It has news rated as false, true, mixed and so on. To test the model, the titles from 2017 were collected from snopes archived news. The current news might not be a good test as news in 2020 might be dominated by current issue such as covid-19 . Thus, to test the model older news was consideded as the training data was also from arround  2017.\n",
    "https://www.snopes.com/?s=2017+archive+news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= [\"Is This James Earl Jones Dressed as Darth Vader\", \n",
    "\"David Rockefeller's Sixth Heart Transplant Successful at Age 99\", \n",
    "\"Did Bloomington Police Discover Over 200 Penises During Raid at a Mortician's Home?\", \n",
    "\"Is the Trump Administration Price Gouging Puerto Rico Evacuees and Seizing Passports?\",\n",
    "\"2017 Tainted Halloween Candy Reports 11/5/2014\", \n",
    "\"Did President Trump Say Pedophiles Will Get the Death Penalty?\", \n",
    "\"Michelle Obama Never Placed Her Hand Over Her Heart During the National Anthem?\",\n",
    "\"Katy Perry Reveals Penchant for Cannibalism?\" ,\n",
    "\"Is a Virginia Church Ripping Out an 'Offensive' George Washington Plaque?\", \n",
    "\"Did Trump Retweet a Cartoon of a Train Hitting a CNN Reporter?\"]\n",
    "\n",
    "label_actual = [\"fake\", \"fake\",\"fake\",\"fake\",\"fake\",\"mixed\", \"fake\",\"fake\",\"mostly_false\",\"true\"] # rated by Snopes\n",
    "label_adjusted = [\"fake\", \"fake\",\"fake\",\"fake\",\"fake\",\"fake\", \"fake\",\"fake\",\"fake\",\"true\"]  # adjusted to fake or true  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and prepaire  Snopes's test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning step for word embeding technique\n",
    "clean_test= [remove_pattern(title, patterns) for title in test]# remove punctuation and other symbols\n",
    "clean_test= [strip_multiple_whitespaces(remove_stopwords(title)) for title in clean_test] # remove stopwords and multiple sapace \n",
    "clean_test= [tokenize_without_stopwords(title) for title in clean_test] # tokenize , lowercase and remove stopwords again\n",
    "\n",
    "# data to be used by countvectorizer and tfidf\n",
    "clean_joined_test = [\" \".join(tokens) for tokens in clean_test] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['james earl jones dressed darth vader',\n",
       " 'david rockefellers sixth heart transplant successful age',\n",
       " 'bloomington police discover penises raid morticians home',\n",
       " 'trump administration price gouging puerto rico evacuees seizing passports',\n",
       " 'tainted halloween candy reports',\n",
       " 'president trump say pedophiles will death penalty',\n",
       " 'michelle obama never placed hand heart national anthem',\n",
       " 'katy perry reveals penchant cannibalism',\n",
       " 'virginia church ripping offensive george washington plaque',\n",
       " 'trump retweet cartoon train hitting cnn reporter']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_joined_test  # cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.128793</td>\n",
       "      <td>0.177201</td>\n",
       "      <td>0.180235</td>\n",
       "      <td>-0.190296</td>\n",
       "      <td>0.253925</td>\n",
       "      <td>0.058876</td>\n",
       "      <td>0.048852</td>\n",
       "      <td>0.191289</td>\n",
       "      <td>-0.271237</td>\n",
       "      <td>-0.038030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151261</td>\n",
       "      <td>-0.059494</td>\n",
       "      <td>-0.077395</td>\n",
       "      <td>-0.037856</td>\n",
       "      <td>-0.094092</td>\n",
       "      <td>0.151805</td>\n",
       "      <td>-0.148135</td>\n",
       "      <td>0.143080</td>\n",
       "      <td>-0.082430</td>\n",
       "      <td>-0.304490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.166258</td>\n",
       "      <td>0.283998</td>\n",
       "      <td>-0.018246</td>\n",
       "      <td>-0.171336</td>\n",
       "      <td>0.098483</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>0.029139</td>\n",
       "      <td>0.142828</td>\n",
       "      <td>-0.128208</td>\n",
       "      <td>-0.149614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>-0.055175</td>\n",
       "      <td>-0.148835</td>\n",
       "      <td>0.123584</td>\n",
       "      <td>-0.077548</td>\n",
       "      <td>0.043160</td>\n",
       "      <td>-0.015674</td>\n",
       "      <td>-0.057001</td>\n",
       "      <td>-0.006010</td>\n",
       "      <td>-0.175042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013336</td>\n",
       "      <td>0.280533</td>\n",
       "      <td>0.302052</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.328273</td>\n",
       "      <td>-0.336396</td>\n",
       "      <td>-0.152405</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>-0.351022</td>\n",
       "      <td>0.149144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>-0.245451</td>\n",
       "      <td>0.750373</td>\n",
       "      <td>-0.109941</td>\n",
       "      <td>0.599421</td>\n",
       "      <td>-0.502533</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.311071</td>\n",
       "      <td>-0.902430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.117074</td>\n",
       "      <td>-0.091639</td>\n",
       "      <td>-0.162477</td>\n",
       "      <td>-0.153316</td>\n",
       "      <td>0.391970</td>\n",
       "      <td>0.218671</td>\n",
       "      <td>-0.157779</td>\n",
       "      <td>0.194142</td>\n",
       "      <td>-0.407429</td>\n",
       "      <td>-0.051375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081282</td>\n",
       "      <td>0.050208</td>\n",
       "      <td>-0.148932</td>\n",
       "      <td>-0.285450</td>\n",
       "      <td>-0.254438</td>\n",
       "      <td>0.388260</td>\n",
       "      <td>0.305041</td>\n",
       "      <td>-0.091261</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>0.100270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.410460</td>\n",
       "      <td>-0.258792</td>\n",
       "      <td>-0.081955</td>\n",
       "      <td>0.180752</td>\n",
       "      <td>0.182197</td>\n",
       "      <td>-0.018268</td>\n",
       "      <td>0.576877</td>\n",
       "      <td>-0.392634</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418954</td>\n",
       "      <td>-0.021041</td>\n",
       "      <td>-0.148664</td>\n",
       "      <td>0.223241</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.351390</td>\n",
       "      <td>-0.140197</td>\n",
       "      <td>0.070729</td>\n",
       "      <td>-0.265066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.128793  0.177201  0.180235 -0.190296  0.253925  0.058876  0.048852   \n",
       "1 -0.166258  0.283998 -0.018246 -0.171336  0.098483  0.056722  0.029139   \n",
       "2 -0.013336  0.280533  0.302052  0.051546  0.328273 -0.336396 -0.152405   \n",
       "3 -0.117074 -0.091639 -0.162477 -0.153316  0.391970  0.218671 -0.157779   \n",
       "4  0.014099  0.410460 -0.258792 -0.081955  0.180752  0.182197 -0.018268   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.191289 -0.271237 -0.038030  ... -0.151261 -0.059494 -0.077395 -0.037856   \n",
       "1  0.142828 -0.128208 -0.149614  ...  0.016323 -0.055175 -0.148835  0.123584   \n",
       "2  0.426667 -0.351022  0.149144  ...  0.012487  0.005410 -0.245451  0.750373   \n",
       "3  0.194142 -0.407429 -0.051375  ...  0.081282  0.050208 -0.148932 -0.285450   \n",
       "4  0.576877 -0.392634  0.024113  ...  0.418954 -0.021041 -0.148664  0.223241   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.094092  0.151805 -0.148135  0.143080 -0.082430 -0.304490  \n",
       "1 -0.077548  0.043160 -0.015674 -0.057001 -0.006010 -0.175042  \n",
       "2 -0.109941  0.599421 -0.502533 -0.007910  0.311071 -0.902430  \n",
       "3 -0.254438  0.388260  0.305041 -0.091261 -0.019325  0.100270  \n",
       "4  0.007106 -0.014250 -0.351390 -0.140197  0.070729 -0.265066  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_test.head() # see the prepaired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize  Snope's test data using tfidf and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count vector and tfidf for snopes test data based on the title and text of news from the training data separately \n",
    "\n",
    "# the first is count vetor for training data and the second is count vector for snopes's data\n",
    "cv_trn_ttl, cv_snp_ttl= get_vector(X_train_ttl, clean_joined_test, CountVectorizer)  \n",
    "cv_trn_txt, cv_snp_txt= get_vector(X_train_txt, clean_joined_test, CountVectorizer)\n",
    "\n",
    "# the first is tfidf vector for training data and the second is for snopes's data\n",
    "cv_trn_tfidf_ttl, cv_snp_tfidf_ttl= get_vector(X_train_ttl, clean_joined_test, TfidfVectorizer)\n",
    "cv_trn_tfidf_txt, cv_snp_tfidf_ttx= get_vector(X_train_txt, clean_joined_test, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize  Snope's test data based on word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase detection and word embeding using the news titles \n",
    "phrase_test= [bigram_ttl[tokens] for tokens in clean_test]              # phrase detection \n",
    "w2v_test = averaged_word_vectorizer(corpus=phrase_test, model=w2v_title,  # word embeding  \n",
    "                                            num_features=feature_size)\n",
    "w2v_test= pd.DataFrame(w2v_test)\n",
    "\n",
    "# phrase detection and word embeding using text data\n",
    "phrase_test_txt= [bigram_txt[tokens] for tokens in clean_test]              # phrase detection \n",
    "w2v_test_txt = averaged_word_vectorizer(corpus=phrase_test_txt, model=w2v_text,  # word embeding  \n",
    "                                            num_features=feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for Snope's test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(x_train,y_train,snp_test, model):\n",
    "    \"\"\"returns the predicted labels and the accuracy\"\"\"\n",
    "    model=model.fit(x_train,y_train )\n",
    "    pred= model.predict(snp_test)\n",
    "    acc=metrics.accuracy_score(label_adjusted, pred) # accuracy \n",
    "    return pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the news based on the text training data using logistic regression and naive bayes\n",
    "# the first value is containes list of predicted labels and the secode is the accuracy\n",
    "pred1, acc1= testing(cv_trn_txt,y_train_txt,cv_snp_txt,LogisticRegression(C=0.8, max_iter=200)) # prediction based on text \n",
    "pred2, acc2= testing(cv_trn_tfidf_txt,y_train_txt,cv_snp_tfidf_ttx,LogisticRegression(C=0.8, max_iter=200))\n",
    "pred3, acc3= testing(cv_trn_txt,y_train_txt,cv_snp_txt,MultinomialNB(alpha=0.001)) # prediction based on title \n",
    "pred4, acc4= testing(cv_trn_tfidf_txt,y_train_txt,cv_snp_tfidf_ttx,MultinomialNB(alpha=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake' 'fake' 'true' 'true' 'fake' 'fake' 'fake' 'fake' 'fake' 'fake']\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#prediction based on word embeding using the title of training data\n",
    "p_w2v_ttl= lreg_model_ttl.predict(w2v_test) # using word2vec features using  title \n",
    "print(p_w2v_ttl)\n",
    "acc_snp_ttl= metrics.accuracy_score(label_adjusted,p_w2v_ttl)\n",
    "print(acc_snp_ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake' 'true' 'fake' 'true' 'fake' 'fake' 'fake' 'fake' 'fake' 'fake']\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#prediction based on word embeding using the text of training data\n",
    "p_w2v_txt= lreg_model_txt.predict(w2v_test_txt)\n",
    "print(p_w2v_txt)\n",
    "acc_snp_txt= metrics.accuracy_score(label_adjusted,p_w2v_txt)\n",
    "print(acc_snp_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate_by_Snopes</th>\n",
       "      <th>countVec_text_lreg</th>\n",
       "      <th>tfidf_text_lreg</th>\n",
       "      <th>countVec_text_NB</th>\n",
       "      <th>tfidf_text_NB</th>\n",
       "      <th>w2v_title_lreg</th>\n",
       "      <th>w2v_text_lreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixed</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mostly_false</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>true</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rate_by_Snopes countVec_text_lreg tfidf_text_lreg countVec_text_NB  \\\n",
       "0            fake               fake            fake             fake   \n",
       "1            fake               fake            fake             fake   \n",
       "2            fake               fake            fake             fake   \n",
       "3            fake               fake            fake             true   \n",
       "4            fake               fake            fake             fake   \n",
       "5           mixed               fake            fake             fake   \n",
       "6            fake               fake            fake             fake   \n",
       "7            fake               fake            fake             fake   \n",
       "8    mostly_false               fake            fake             fake   \n",
       "9            true               fake            fake             fake   \n",
       "10            NaN                0.9             0.9              0.8   \n",
       "\n",
       "   tfidf_text_NB w2v_title_lreg w2v_text_lreg  \n",
       "0           fake           fake          fake  \n",
       "1           fake           fake          true  \n",
       "2           fake           true          fake  \n",
       "3           true           true          true  \n",
       "4           fake           fake          fake  \n",
       "5           fake           fake          fake  \n",
       "6           fake           fake          fake  \n",
       "7           fake           fake          fake  \n",
       "8           fake           fake          fake  \n",
       "9           fake           fake          fake  \n",
       "10           0.8            0.7           0.7  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pack all the predictions  together \n",
    "pred_labeles=[[a,b,c, d,e, f] for a,b,c, d,e,f in zip(pred1,pred2,pred3,pred4, p_w2v_ttl, p_w2v_txt)] \n",
    "\n",
    "#bring all the accuraries together \n",
    "pred_accuracy= [acc1, acc2, acc3, acc4, acc_snp_ttl, acc_snp_txt]\n",
    "\n",
    "pred_labeles.append(pred_accuracy) # append the accuracy at the end \n",
    "\n",
    "snp_summary= pd.DataFrame(pred_labeles, columns=[\"countVec_text_lreg\",\"tfidf_text_lreg\",\"countVec_text_NB\", \"tfidf_text_NB\", \"w2v_title_lreg\",\"w2v_text_lreg\" ])\n",
    "\n",
    "#concatnate the actual labeling by Snopses with the predicted labeling \n",
    "snp_summary= pd.concat((pd.Series(label_actual, name=\"Rate_by_Snopes\"),snp_summary), axis=1) \n",
    "\n",
    "snp_summary.to_csv(\"snp_prediction_summary2.csv\") # save the result\n",
    "snp_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Appendix: Parameter tunning for multinomial naive bayes and  logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, model, param_grid):\n",
    "    \n",
    "    grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    cv=5)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    print('Best Score: ', grid_result.best_score_)\n",
    "    print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vect(data, min_df):\n",
    "    \"\"\"returns the CountVectorizer object and the fitted count vector of the data with \n",
    "    the given number of minimum document frequancy.\n",
    "    parameter:\n",
    "    -------\n",
    "        data : collection of text document\n",
    "        min_df : the minimum document frequency when building the vocabulary \"\"\"\n",
    "    \n",
    "    cv= CountVectorizer(stop_words=\"english\", min_df=min_df)\n",
    "    trans= cv.fit_transform(data)\n",
    "    return cv, trans\n",
    "\n",
    "def tfidf_vect(data, min_df): # tfidf vectorizer \n",
    "    cv= TfidfVectorizer(stop_words=\"english\", min_df=min_df)\n",
    "    trans= cv.fit_transform(data)\n",
    "    return cv, trans\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameter \"C\" (Inverse of regularization strength) for Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count vectors for the cleaned title and the text\n",
    "#vecr_ttl, feat_v_ttl= count_vect(X_train_ttl,3) #  \n",
    "#vecr_txt, feat_v_txt= count_vect(X_train_txt,3)\n",
    "vec_tfidf_ttl, feat_v_tfidf_ttl= tfidf_vect(X_train_ttl,3)\n",
    "vec_tfidf_txt, feat_v_tfidf_txt= tfidf_vect(X_train_txt,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vecr, feat_nc_txt= count_vect(X_train[\"text\"],3)\n",
    "vttl, feat_nc_ttl= count_vect(X_train[\"title\"],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9448579523234949\n",
      "Best Params:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# not clean, count vector, title\n",
    "param_grid={\"C\":[0.001,0.01,0.1,0.2,0.4,0.5,0.8,1]}\n",
    "grid_search(feat_nc_ttl, y_train, LogisticRegression(max_iter=200),param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.944221536614178\n",
      "Best Params:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Tunning hypermarameter for logistic regression , cleaned title\n",
    "param_grid={\"C\":[0.001,0.01,0.1,0.2,0.4,0.5,0.8,1]}\n",
    "grid_search(feat_v_ttl, y_train_ttl, LogisticRegression(max_iter=200),param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9948453901549351\n",
      "Best Params:  {'C': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Tunning hypermarameter for logistic regression, cleaned text \n",
    "param_grid={\"C\":[0.001,0.01,0.1,0.2,0.4,0.5,0.8,1]}\n",
    "grid_search(feat_v_txt, y_train_txt, LogisticRegression(max_iter=200),param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.938430511059796\n",
      "Best Params:  {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "# tfidf, clean title\n",
    "param_grid={\"C\":[0.001,0.01,0.1,0.2,0.4,0.5,0.8,1]}\n",
    "grid_search(feat_v_tfidf_ttl, y_train, LogisticRegression(max_iter=200),param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   17.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9835497149782408\n",
      "Best Params:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# tfidf, clean, text\n",
    "param_grid={\"C\":[0.001,0.01,0.1,0.2,0.4,0.5,0.8,1]}\n",
    "grid_search(feat_v_tfidf_txt, y_train, LogisticRegression(max_iter=200),param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameter \"alpha\" (additive smoothing parameter) for Multinomial Naive Bayes model\n",
    "\n",
    "The parameter alpha is selected based on grid search crossvalidation. Alpha is set 0.5 for prediction based on title and 0.001 for prediction based on text. However, the default value also gave similar result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9374759836800649\n",
      "Best Params:  {'alpha': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Tunning hypermarameter for Multinomial Naive Bayes , title \n",
    "param_grid = {\"alpha\": [0.001,0.01,0.1,0.2,0.5,0.8,1,2]}\n",
    "grid_search(feat_v_ttl, y_train_ttl, MultinomialNB(),param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9570764444532192\n",
      "Best Params:  {'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Tunning hypermarameter for Multinomial Naive Bayes , text \n",
    "param_grid = {\"alpha\": [0.001,0.01,0.1,0.2,0.5,0.8,1,2]}\n",
    "grid_search(feat_v_txt, y_train_txt, MultinomialNB(),param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9341349783876532\n",
      "Best Params:  {'alpha': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"alpha\": [0.001,0.01,0.1,0.2,0.5,0.8,1,2]}\n",
    "grid_search(feat_v_tfidf_ttl, y_train, MultinomialNB(),param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9485489467698672\n",
      "Best Params:  {'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"alpha\": [0.001,0.01,0.1,0.2,0.5,0.8,1,2]}\n",
    "grid_search(feat_v_tfidf_txt, y_train, MultinomialNB(),param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
