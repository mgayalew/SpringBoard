{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting Fake are Real News - Modeling and testing \n",
    "\n",
    "\n",
    "                                By: Muluemebet Ayalew \n",
    "                                    June, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # to use regular expression pattern \n",
    "import datetime as dt  # to parse to datetime\n",
    "import string\n",
    "from scipy import stats\n",
    "\n",
    "#text processing and visualization\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize, TweetTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords          # to access stop words \n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer   # for lemmatization or steming\n",
    "\n",
    "import spacy\n",
    "from gensim.corpora.dictionary import Dictionary   # to map token , id and create corpus\n",
    "from sklearn.manifold import TSNE\n",
    "#from wordcloud import WordCloud,STOPWORDS # to visualize frequeent words \n",
    "from gensim.models import  Word2Vec  #  word embeding \n",
    "from gensim.models.phrases import Phraser, Phrases # to use for bigram modeling,\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.tfidfmodel import TfidfModel # tfidf using gensim\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # to make word vectors \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# For modeling and evaluation \n",
    "from sklearn.naive_bayes import MultinomialNB  # for Naive Baye's  classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics # to evaluate model performance\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Read the data"
    "Data source: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true= pd.read_csv(\"True.csv\", parse_dates=[\"date\"])     # the true news data\n",
    "fake= pd.read_csv(\"Fake.csv\")     # the fake news data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "\n",
       "                                                text       subject       date  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews 2017-12-31  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews 2017-12-29  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews 2017-12-31  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head(3) # the first few rows of real dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape # shape of real news before adding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head() # the first few rows of fake dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape  # shape of fake news before adding label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Add labels(fake/true) to the  dataframs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called is_fake and label as 0 for true news \n",
    "true[\"label\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called is_fake and label as 1 for fake news \n",
    "fake[\"label\"]= \"fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the date column into datetime. \n",
    "#Since it has two datetime format, we need two formats to parse.  \n",
    "def parsing_datetime(string):\n",
    "    for f in (\"%B %d, %Y\", '%d-%b-%y', \"%b %d, %Y\"): # format  19-Feb-18\n",
    "        try:\n",
    "            return dt.datetime.strptime(string, f)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "# parse the date column of fake dataframe into datetime\n",
    "fake.date= fake.date.apply(lambda x: parsing_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "\n",
       "                                                text       subject       date  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews 2017-12-31   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews 2017-12-29   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews 2017-12-31   \n",
       "\n",
       "  label  \n",
       "0  true  \n",
       "1  true  \n",
       "2  true  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "\n",
       "                                                text subject       date label  \n",
       "0  Donald Trump just couldn t wish all Americans ...    News 2017-12-31  fake  \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News 2017-12-31  fake  \n",
       "2  On Friday, it was revealed that former Milwauk...    News 2017-12-30  fake  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2)  Merge the real and fake dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the fake and read dataframe\n",
    "news= pd.concat([true,fake], axis=0, ignore_index=True)#.reset_index() # reset index to have unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject       date  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews 2017-12-31   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews 2017-12-29   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews 2017-12-31   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews 2017-12-30   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews 2017-12-29   \n",
       "\n",
       "  label  \n",
       "0  true  \n",
       "1  true  \n",
       "2  true  \n",
       "3  true  \n",
       "4  true  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19764</th>\n",
       "      <td>Far-right party likened to Nazis to shake up G...</td>\n",
       "      <td>FRANKFURT AN DER ODER, Germany (Reuters) - The...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>California or bust: Bernie Sanders charts a Wh...</td>\n",
       "      <td>NEW YORK (Reuters) - Defying opinion polls and...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>‘Family Values’ GOPer Sexually Harasses Inter...</td>\n",
       "      <td>Social conservatives run campaigns and win ele...</td>\n",
       "      <td>News</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>Tight race as South Africa's ANC prepares to e...</td>\n",
       "      <td>JOHANNESBURG (Reuters) - South Africa s ruling...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19219</th>\n",
       "      <td>New Zealand Labour leader says will not yet co...</td>\n",
       "      <td>WELLINGTON (Reuters) - New Zealand Labour lead...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "19764  Far-right party likened to Nazis to shake up G...   \n",
       "9986   California or bust: Bernie Sanders charts a Wh...   \n",
       "29001   ‘Family Values’ GOPer Sexually Harasses Inter...   \n",
       "12484  Tight race as South Africa's ANC prepares to e...   \n",
       "19219  New Zealand Labour leader says will not yet co...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "19764  FRANKFURT AN DER ODER, Germany (Reuters) - The...     worldnews   \n",
       "9986   NEW YORK (Reuters) - Defying opinion polls and...  politicsNews   \n",
       "29001  Social conservatives run campaigns and win ele...          News   \n",
       "12484  JOHANNESBURG (Reuters) - South Africa s ruling...     worldnews   \n",
       "19219  WELLINGTON (Reuters) - New Zealand Labour lead...     worldnews   \n",
       "\n",
       "            date label  \n",
       "19764 2017-09-17  true  \n",
       "9986  2016-04-11  true  \n",
       "29001 2016-03-10  fake  \n",
       "12484 2017-12-12  true  \n",
       "19219 2017-09-24  true  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.sample(5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.index.is_unique # we have unique index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot the number of fake and real news\n",
    "_=news.label.value_counts().plot(kind=\"bar\", title=\"Frequency of Fake and Real News\")\n",
    "_=plt.ylabel(\"Number of News\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)  Data Cleaning and preprocessing:\n",
    "Removing html tags, url links, specal characters, punctuations, emoji and stopwords. Though CountVectorizer handles stop words , special characters and punctuation, the cleaning was done before it. \n",
    "\n",
    "The function remove_pattern is defiend to remove certain patterns from the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function to remove patterns(emoji, url, html , special characteres, punctuations, .....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patterns= [emoji, url, html]\n",
    "def remove_pattern(text, patterns):\n",
    "    \"\"\"The function remove_pattern returns the new string with a set of patterns removed.\n",
    "       Parameters:\n",
    "       ------------\n",
    "       data: the text from which the pattern will be removed\n",
    "       patterns: is the set of patterns(iterable) we are intereted to remove from the text\n",
    "       \"\"\"\n",
    "           \n",
    "    for pattern in patterns:\n",
    "        new= re.sub(pattern, \"\", text)\n",
    "        text= new \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns to be extracted and to be removed from the data \n",
    "emoji = \"[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF\\U000024C2-\\U0001F251]+\"\n",
    "\n",
    "url= re.compile(\"https?://\\S+|www\\.\\S+\")                     # pattern for url\n",
    "html= r'<.*?>'                                               # pattern for html tag\n",
    "num_with_text= r\"\\S*\\d+\\S*\"                                  # pattern for digit \n",
    "punctuation= r\"[#@&%$~=\\.;:\\?,(){}\\\"\\“\\”\\‘\\'\\*!\\+`^<>\\[\\]\\-]+\"      #pattern for punctuations and special characters   \n",
    "apostroph=r\"\\’s?\"\n",
    "# collect the patterns \n",
    "patterns=[emoji, url, html, num_with_text, punctuation, apostroph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Clean merged data\n",
    "At this statage of data cleaning ,the emoji, url links, html tag, digits and special characters and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the title of merged data using regular expression patterns\n",
    "news_clean_title = news.title.apply(remove_pattern, patterns= patterns)\n",
    "news_clean_text= news.text.apply(remove_pattern, patterns= patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://mc.ai/a-guide-to-simple-text-classification-with-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepaire the data in the same format as BERT requires \n",
    "bert= news # copy the news to BERT \n",
    "bert[\"id\"]= bert.index # add unique id for each row\n",
    "dicmap= {\"true\": 0, \"fake\": 1} # lable true news as 0 and fake news as 1\n",
    "bert[\"is_fake\"] =news.label.apply(lambda x: dicmap[x]) \n",
    "bert[\"constant\"]=[\"a\"]*news.shape[0] # create a constant \n",
    "\n",
    "bert= bert[[\"id\", \"is_fake\",\"constant\", \"title\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>constant</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_fake constant                                              title  \\\n",
       "0   0        0        a  As U.S. budget fight looms, Republicans flip t...   \n",
       "1   1        0        a  U.S. military to accept transgender recruits o...   \n",
       "2   2        0        a  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "\n",
       "                                                text  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.head(3) # now we have similar format for BERT. But we have two text columns title and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splite the data into training, validating and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, validate_data, test_data (80%, 10%, 10% respectively)\n",
    "train_data, validate_data, test_data= np.split(bert.sample(frac=1, random_state=42), [ int(.8*len(news)), int(.9*len(news))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4490, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4490, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save training, validating and test data in the way BERT requires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data with BERT format (title)\n",
    "bert_train_ttl= train_data.drop(\"text\", axis=1).to_csv(\"split_data_title/train.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "# training data with BERT format (text)\n",
    "bert_train_txt= train_data.drop(\"title\", axis=1).to_csv(\"split_data_text/train.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "#validating data\n",
    "bert_valid_ttl= validate_data.drop(\"text\", axis=1).to_csv(\"split_data_title/dev.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "bert_valid_txt= validate_data.drop(\"title\", axis=1).to_csv(\"split_data_text/dev.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "#test data\n",
    "bert_test_ttl=test_data[[\"id\", \"title\"]].to_csv(\"split_data_title/test.tsv\",sep=\"\\t\", index=False, header=True) \n",
    "bert_test_txt=test_data[[\"id\",\"text\"]].to_csv(\"split_data_text/test.tsv\",sep=\"\\t\",index=False, header=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Using bert- serving- server\n",
    "#### Reference : https://github.com/hanxiao/bert-as-service\n",
    "#### Steps to use bert \n",
    "    - pip install bert-serving-server  # server\n",
    "    - pip install bert-serving-client  # client, independent of `bert-serving-server`\n",
    "    -!bert-serving-start -model_dir /uncased_L-12_H-768_A-12/ -num_worker=4 \n",
    "    - install bert_serving \n",
    "    - from bert_serving.client import BertClient\n",
    "    - bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: /home/mulu/bert/bin/bert-serving-start -model_dir /home/mulu/notebooks/uncased_L-12_H-768_A-12/uncased_L-12_H-768_A-12/ -num_worker=1\n",
      "                 ARG   VALUE\n",
      "__________________________________________________\n",
      "           ckpt_name = bert_model.ckpt\n",
      "         config_name = bert_config.json\n",
      "                cors = *\n",
      "                 cpu = False\n",
      "          device_map = []\n",
      "       do_lower_case = True\n",
      "  fixed_embed_length = False\n",
      "                fp16 = False\n",
      " gpu_memory_fraction = 0.5\n",
      "       graph_tmp_dir = None\n",
      "    http_max_connect = 10\n",
      "           http_port = None\n",
      "        mask_cls_sep = False\n",
      "      max_batch_size = 256\n",
      "         max_seq_len = 25\n",
      "           model_dir = /home/mulu/notebooks/uncased_L-12_H-768_A-12/uncased_L-12_H-768_A-12/\n",
      "no_position_embeddings = False\n",
      "    no_special_token = False\n",
      "          num_worker = 1\n",
      "       pooling_layer = [-2]\n",
      "    pooling_strategy = REDUCE_MEAN\n",
      "                port = 5555\n",
      "            port_out = 5556\n",
      "       prefetch_size = 10\n",
      " priority_batch_size = 16\n",
      "show_tokens_to_client = False\n",
      "     tuned_model_dir = None\n",
      "             verbose = False\n",
      "                 xla = False\n",
      "\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n",
      "WARNING:tensorflow:From /home/mulu/bert/lib/python3.7/site-packages/bert_serving/server/helper.py:186: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mulu/bert/lib/python3.7/site-packages/bert_serving/server/helper.py:186: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: /home/mulu/notebooks/uncased_L-12_H-768_A-12/uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: /home/mulu/notebooks/uncased_L-12_H-768_A-12/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /tmp/tmpko9p2qcx\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /tmp/tmpko9p2qcx\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /tmp/tmpko9p2qcx\n",
      "WARNING:tensorflow:From /home/mulu/bert/lib/python3.7/site-packages/bert_serving/server/helper.py:186: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mulu/bert/lib/python3.7/site-packages/bert_serving/server/helper.py:186: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'887a133a-8b6e-4f4b-92f2-612daf00977c'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'887a133a-8b6e-4f4b-92f2-612daf00977c'\n",
      "^C\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "Process BertSink-2:\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mulu/bert/bin/bert-serving-start\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/mulu/bert/lib/python3.7/site-packages/bert_serving/server/cli/__init__.py\", line 5, in main\n",
      "    server.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bert-serving-start -model_dir /uncased_L-12_H-768_A-12/ -num_worker=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert_serving in /home/mulu/bert/lib/python3.7/site-packages (0.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/mulu/bert/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_serving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-41c13ad0546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#3:42 pm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#bc = BertClient(ip='142.93.15.94')#, port=5555, port_out=5556)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#bc.encode(['First do it', 'then do it right', 'then do it better'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ip, port, port_out, output_fmt, show_server_config, identity, check_version, check_length, check_token_info, ignore_all_checks, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_all_checks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_version\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshow_server_config\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_length\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_token_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0ms_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_version\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36marg_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVTIMEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 t_e = TimeoutError(\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36mserver_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0mreq_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'SHOW_CONFIG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# receive a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVMORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bc = BertClient()\n",
    "#3:42 pm\n",
    "#bc = BertClient(ip='142.93.15.94')#, port=5555, port_out=5556)\n",
    "#bc.encode(['First do it', 'then do it right', 'then do it better'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : \n",
    "the BertClient() takes long to instanciate and unable to see the result , with/without port "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2) using bert's run_classifier.py \n",
    "#### Reference :  https://mc.ai/a-guide-to-simple-text-classification-with-bert/\n",
    "https://towardsdatascience.com/multi-class-sentiment-analysis-using-bert-86657a2af156\n",
    "\n",
    "For this approach:\n",
    " - we need to download bert from https://github.com/google-research/bert.git\n",
    " - we need to download 'bert-base-uncased'\n",
    " - the input data has to be converted into .tsv(tab separated file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "only_check_args",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/Trash/files/bert/run_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    991\u001b[0m   \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_flag_as_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert_config_file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m   \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_flag_as_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_dir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#was tf.app.run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    291\u001b[0m     args = _run_init(\n\u001b[1;32m    292\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mflags_parser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0m_init_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_init\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    360\u001b[0m   args = _register_and_parse_flags_with_usage(\n\u001b[1;32m    361\u001b[0m       \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags_parser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   )\n\u001b[1;32m    364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfaulthandler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36m_register_and_parse_flags_with_usage\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0;31m# Exit when told so.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monly_check_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0;31m# Immediately after flags are parsed, bump verbosity to INFO if the flag has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bert/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mfl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__hiddenflags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: only_check_args"
     ]
    }
   ],
   "source": [
    "# Reference from my pc \n",
    "%run run_classifier.py \\\n",
    "--task_name=cola \\\n",
    "--do_train=true \\\n",
    "--do_eval=true \\\n",
    "--data_dir=\"split_data_title/\" \\\n",
    "--vocab_file=\"uncased_L-12_H-768_A-12/vocab.txt\" \\\n",
    "--bert_config_file=\"uncased_L-12_H-768_A-12/bert_config.json\" \\\n",
    "--init_checkpoint=\"uncased_L-12_H-768_A-12/bert_model.ckpt\" \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size=32 \\\n",
    "--learning_rate=2e-5 \\\n",
    "--num_train_epochs=3.0 \\\n",
    "--output_dir=\"bert_output/\" \\\n",
    "--do_lower_case=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result using run_classifier.py : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3) Binary classification \n",
    "\n",
    "#### Reference: \n",
    "https://medium.com/swlh/a-simple-guide-on-using-bert-for-text-classification-bbf041ac8d04#:~:text=%20A%20Simple%20Guide%20On%20Using%20BERT%20for,the%20meal%2C%20we%20need%20to%20prepare...%20More%20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "#import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "csv.field_size_limit(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                if sys.version_info[0] == 2:\n",
    "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "\n",
    "class BinaryClassificationProcessor(DataProcessor):\n",
    "    \"\"\"Processor for binary classification dataset.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    \n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            #guid= line[]\n",
    "            text_a = line[3]\n",
    "            label = line[1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def convert_example_to_feature(example_row):\n",
    "    # return example_row\n",
    "    example, label_map, max_seq_length, tokenizer, output_mode = example_row\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "    tokens_b = None\n",
    "    if example.text_b:\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "        # length is less than the specified length.\n",
    "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "    else:\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "    segment_ids = [0] * len(tokens)\n",
    "\n",
    "    if tokens_b:\n",
    "        tokens += tokens_b + [\"[SEP]\"]\n",
    "        segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    padding = [0] * (max_seq_length - len(input_ids))\n",
    "    input_ids += padding\n",
    "    input_mask += padding\n",
    "    segment_ids += padding\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    if output_mode == \"classification\":\n",
    "        label_id = label_map[example.label]\n",
    "    elif output_mode == \"regression\":\n",
    "        label_id = float(example.label)\n",
    "    else:\n",
    "        raise KeyError(output_mode)\n",
    "\n",
    "    return InputFeatures(input_ids=input_ids,\n",
    "                         input_mask=input_mask,\n",
    "                         segment_ids=segment_ids,\n",
    "                         label_id=label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "#from tools import * # the above classs and functions\n",
    "#import convert_examples_to_features # the above classs and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"split_data_title/\" \n",
    "# Bert pre-trained model, bert-base-uncased, \n",
    "BERT_MODEL = \"uncased_L-12_H-768_A-12/\"\n",
    "\n",
    "\n",
    "# The name of the task to train.\n",
    "TASK_NAME = 'news'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = OUTPUT_MODE\n",
    "\n",
    "cache_dir = CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-783448f03236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_examples_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-02f4277188fe>\u001b[0m in \u001b[0;36mget_train_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"\"\"See base class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         return self._create_examples(\n\u001b[0;32m---> 55\u001b[0;31m             self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-02f4277188fe>\u001b[0m in \u001b[0;36m_create_examples\u001b[0;34m(self, lines, set_type)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mguid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m#guid= line[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mtext_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             examples.append(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "processor = BinaryClassificationProcessor()\n",
    "train_examples = processor.get_train_examples(DATA_DIR)\n",
    "train_examples_len = len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_train_optimization_steps = int(\n",
    "#   train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd=pd.read_csv(\"split_data_title/train.tsv\", sep=\"\\t\", names=[\"id\", \"label\", \"alpha\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22216</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>BREAKING: GOP Chairman Grassley Has Had Enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27917</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Failed GOP Candidates Remembered In Hilarious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25007</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Mike Pence’s New DC Neighbors Are HILARIOUSLY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>California AG pledges to defend birth control ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32476</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>AZ RANCHERS Living On US-Mexico Border Destroy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label alpha                                              title\n",
       "0  22216      1     a   BREAKING: GOP Chairman Grassley Has Had Enoug...\n",
       "1  27917      1     a   Failed GOP Candidates Remembered In Hilarious...\n",
       "2  25007      1     a   Mike Pence’s New DC Neighbors Are HILARIOUSLY...\n",
       "3   1377      0     a  California AG pledges to defend birth control ...\n",
       "4  32476      1     a  AZ RANCHERS Living On US-Mexico Border Destroy..."
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mulu/notebooks/split_data_title/train.tsv\n"
     ]
    }
   ],
   "source": [
    "#for debuging purpose \n",
    "a= os.path.join(DATA_DIR, \"train.tsv\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['22216', '1', 'a', ' BREAKING: GOP Chairman Grassley Has Had Enough, DEMANDS Trump Jr. Testimony'], ['27917', '1', 'a', ' Failed GOP Candidates Remembered In Hilarious Mocking Eulogies (VIDEO)'], ['25007', '1', 'a', ' Mike Pence’s New DC Neighbors Are HILARIOUSLY Trolling Him For Being A Homophobic Bigot'], ['1377', '0', 'a', 'California AG pledges to defend birth control insurance coverage']]\n"
     ]
    }
   ],
   "source": [
    "tsv=processor._read_tsv(a)\n",
    "print(tsv[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Adapted from multiclass classifiers \n",
    "#### Reference : https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'fake'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2088, 1012, 2023, 2003, 2033, 1012, 2023, 2003, 2153, 2033, 102]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"hello world. this is me .This is again me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepaire the data \n",
    "dicmap= {\"true\": 0, \"fake\": 1} # lable true news as 0 and fake news as 1\n",
    "news[\"is_fake\"] =news.label.apply(lambda x: dicmap[x]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42742</th>\n",
       "      <td>Why French Legal System Turned Down Village’s ...</td>\n",
       "      <td>Christians don t decapitate their bosses Well...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>Trump replaces chief of staff Priebus with ret...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>true</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30192</th>\n",
       "      <td>Dark Money: Ted Cruz Bought His Senate Seat W...</td>\n",
       "      <td>Republican presidential candidate Ted Cruz (R-...</td>\n",
       "      <td>News</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "42742  Why French Legal System Turned Down Village’s ...   \n",
       "2416   Trump replaces chief of staff Priebus with ret...   \n",
       "30192   Dark Money: Ted Cruz Bought His Senate Seat W...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "42742   Christians don t decapitate their bosses Well...     left-news   \n",
       "2416   WASHINGTON (Reuters) - President Donald Trump ...  politicsNews   \n",
       "30192  Republican presidential candidate Ted Cruz (R-...          News   \n",
       "\n",
       "            date label  is_fake  \n",
       "42742 2015-11-16  fake        1  \n",
       "2416  2017-07-28  true        0  \n",
       "30192 2016-01-13  fake        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fake</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>19959</td>\n",
       "      <td>19959</td>\n",
       "      <td>19959</td>\n",
       "      <td>19949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3522</td>\n",
       "      <td>3522</td>\n",
       "      <td>3522</td>\n",
       "      <td>3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">true</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>18204</td>\n",
       "      <td>18204</td>\n",
       "      <td>18204</td>\n",
       "      <td>18204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title   text  subject   date\n",
       "label is_fake data_type                              \n",
       "fake  1       train      19959  19959    19959  19949\n",
       "              val         3522   3522     3522   3522\n",
       "true  0       train      18204  18204    18204  18204\n",
       "              val         3213   3213     3213   3213"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training and validating data\n",
    "Xb_train, Xb_val, yb_train, yb_val= train_test_split(news.index.values,news.is_fake, test_size=0.15, random_state=40, stratify=news.is_fake)\n",
    "\n",
    "news['data_type'] = ['not_set']*news.shape[0]\n",
    "\n",
    "news.loc[Xb_train, 'data_type'] = 'train'\n",
    "news.loc[Xb_val, 'data_type'] = 'val'\n",
    "\n",
    "news.groupby(['label', 'is_fake', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "   news[news.data_type==\"train\"].title.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt', truncation=True\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    news[news.data_type==\"val\"].title.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    "    ,truncation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38163, 256])\n",
      "torch.Size([6735, 256])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data_train['input_ids'].shape)\n",
    "print(encoded_data_val['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38163,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(news[news.data_type=='train'].is_fake.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(news[news.data_type=='val'].is_fake.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(dicmap),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in dicmap.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is obtained from binary classification aproach \n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4250a283363f4d779c98e26563e8d6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61813ff84a474ffaae821fb8d312f416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=12721.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "    \n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Result:\n",
    "The Kernel died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(dicmap),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('data_volume/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google Colaboratory , using transformers module \n",
    "I used google colab and got memmory issue. Will continue working on google colab using transformers  \n",
    "Reference: \n",
    "https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
